##Review of Sources Related to the Domain
The speed, and the convenience, of networks in recent years - the prevalence of wireless networking and the omnipresence of the Internet - has lent itself to the way people obtain and subsequently consume their content. Major news corporations - the BBC, Sky, CNN, and so on - have been widespread across the Web for many years, and many Web users prefer to get their news through these sources rather than through traditional means such as television channels or newspapers. In the same way, people frequent record stores less and less. The early 21st century brought around Peer-to-Peer (P2P) networks for downloading files such as Napster and Kazaa, and shortly thereafter came the iTunes Store (Alves K. and Michael, K. 2005). Likewise for movies and TV shows - high street store chains selling such media have been dwindling in recent years as more and more people turn to purchasing content online, or using streaming services. And similarly once more for games, with the Steam application or services like the former Direct2Drive (D2D) (Toivonen S. and Sotamaa, O., 2010).

Games-on-demand have actually been around for longer than their Video (VOD) counterparts - indeed the first games available for digital distribution came about in 1983 with the GameLine rental service for the Atari 2600 (Skelton, D. (n.d.)). In contrast, the first VOD service didn't come about until late 1994 (Rajapakshe, H. and Quec, D.P., 1995). While today, most of the kinks in the modern variants of these services (Steam, the Xbox Live Marketplace or Netflix to name a few) have been worked out, allowing these services to provide a clean, easy and fast user experience (UX), the services have yet to take on fully widespread adoption in the same way as, say, the iTunes Music Store has (which became the largest music retailer in the United States in 2008) (Apple Inc., 2008). A factor of this problem may in fact have something to do with one of the causes of services' prevalence: the recent boom in the speed of the Internet.

Or, more precisely, the boom in the speed of the Internet *in most areas*. To use an example, while devices sporting 3G or 4G radios are easily capable of downloading data at incredibly high speeds even over the air, this is on the proviso that the radio is in an area with good signal coverage. Similarly with home broadband connections - while connection speeds are in many areas fast enough to, say, download a HD movie in a reasonable amount of time, or stream it with any level of quality of service, in other households with lesser connections downloading can become an overnight affair, and streaming can be completely out of the question. Obtaining our media through the Internet, and not in physical form, is undoubtedly the future. Just in some places, infrastructures aren't ready for the future yet.

As technology in content distribution hurtles further and further towards streaming services the quality and bandwidth of the internet connection in question becomes more and more important. Even streaming services for gaming have made an appearance recently - OnLive is a service allowing 'cloud gaming', streaming the output and input in realtime to and from a thin client, that became available to the public in 2010 (OnLive, Inc., 2010). Once again, perfectly brilliant with any reasonable amount of connectivity and wholly unusable on lower-end connections. 

In the United Kingdom, a recent study found that over a third of the country are suffering with these sub-par broadband speeds - this being defined by "under 5Mb/s" (BBC News, 2012). Assuming someone has a connection speed of 5Mb/s, we can work out how long it would take them to download, say, *Portal 2* (which when downloaded from Steam is 11.3GB).
<div>
<figure>
<img style="width: 30%" src="img/equation.png"> = 18080 seconds = 5 hours 1 minute
<figcaption>Downloading *Portal 2* on a slow connection</figcaption>
</figure>
</div>
5 hours is a best-case scenario, too, since a whole third of UK postcodes have significantly slower connections than even this. On this connection or even on speedy connections, though, other issues such as packet loss can prevent quality service; if packets are not received they must be requested and sent again, which significantly increases the amount of time a resource can take to download. Waiting for this long for entertainment is something consumers have not had to do in the past, and currently it is the trade-off made for the convenience of digital media over its yesteryear physical formats.

And indeed there really is no time for consumers to wait for these things. The average age of a video game player, for example, is 37 - the stereotype of teenage boy gamers is a misconception: they only make up 13% of the population of gamers compared to 37% for females above the age of 18 (ESA, 2011). The 'average' gamer is likely to be an adult with a job, gaming for some escapism, who importantly does not have five hours spare after his working day to wait for a game to download.

##Review of Research and Development methods
###Development Methodologies
During the development phase of the project, the design decisions and the plans drawn up will be used to produce an actual working artefact. However, it is always a good idea to, before diving into coding a program, work out a methodology to help the project's structure and to help control the creation process, from gathering of requirements right through to the final QA phase of development before project completion. This structure can be the difference between a project's success or failure, primarily by improving a team's productivity and focus - since everybody is working in the same method, and following the same contingency plans - and as such there are many methodologies to choose from, each with their own characteristics. No one methodology can therefore be applied to a particular project, particularly when projects' scales and goals can be so different. While development methodologies were first created for working with large-scale projects, as more and more come into existence, and as older, robust methodologies are adapted, they can often work with small, or in this case one-man projects as well to an extent, perhaps with some adaptation.

####Pure Waterfall
The waterfall methodology was developed in 1970 by Winston. W. Royce, as a sequential process to follow throughout the development process. It consists of several clearly-defined phases, each of which must be completed before the next can start. These are:

1.	Requirements Specification
2.	Design
3.	Construction (i.e. implementation)
4.	Integration
5.	Testing and debugging
6.	Installation
7.	Maintenance

The waterfall model was used as a base in developing the structure of other methodologies, particularly those that also permit a similar sequential flow of phases (Royce, W.W., 1970). The rigid structure of the waterfall is useful for producing a product of high quality, as each phase of development must be entirely complete and without problems before moving onto the next phase. It also works well when the development team are technically weak, allowing them to concentrate on one thing at a time, and the structure lends itself well when the team is spread overseas - although not relevant in this instance. However, this rigid progression has some shortfalls also, most obviously in its inflexibility if the requirements change. In fact, seeing as the requirements must be set in stone before even moving forward on to the next step, they must all be defined at the outset. This can often be difficult, to say the least - requirements often change as work progresses and more information on its scope becomes apparent. Additionally, as the integration and testing phases are towards the end of the lifecycle, often it's not possible to 'see' the program in action until then. It's possible that, by this point, any changes a customer desires are impossible, or at the least extremely costly, to commit to (McConnell, S., 1996). 

However, there are as previously mentioned many development methodologies, many of which are not as strictly iterative as 'pure' waterfall. Other Software Development Lifecycles (SDLCs) can take radically different approaches and thus can be extremely more adaptable for use projects where waterfall is simply unsuitable. The phases of these different lifecycles, while getting the same job done as in waterfall, can vary vastly in how much focus is put on them, the order in which they occur, and most importantly how they can be adapted as development goes on.

####Agile & Scrum
Agile methodology is becoming extremely popular in businesses worldwide. It is a model in which the end users and developers are in close and regular communication, making it very good for gathering and adapting to customer feedback. Because this rapport needs to be built up, it works best with small teams of developers. Testing is carried out throughout the development process, as opposed to in a lump after the main development has been completed. This testing can be split into two different kinds: user acceptance testing as well as unit testing for the developers' benefit. Various forms of and variations upon Agile development have been proposed, the emergent variant being Scrum methodology (Cockburn, A., 2006).

Scrum methodology involves assigning certain roles to individuals and splitting the workload in a certain way. One developer is assigned the title of the 'Scrum Master', who has the job of ensuring that the process is followed correctly, and a customer is assigned as the product owner, or primary stakeholder: the point of contact between the development team and the user base - the customers' spokesman. The work is split into 'sprints' - a unit of development with a specific objective, which should last a few weeks. Before each sprint, a meeting is held to determine what should be completed by its end. During a sprint, the requirements are not allowed to change, so if they have changed the issue must be raised in this meeting. Every day or few days during the sprint a short meeting, or scrum, is held, in which any customer is welcome, not just the product owner. During this, the development team members give progress updates on what they have achieved since the last scrum and what they intend to do next. After a sprint another meeting is held to review what was accomplished and demonstrate any new working features to the product owner (Schwaber, K., 1995).

Agile's incremental structure, alongside its provision for changes in requirements at certain points, is a very desirable thing to have. However, pulling this off requires very close monitoring by project managers and (if using Scrum) the Scrum Master, and often requires better quality developers than other, simpler methodologies. Given the correct resources, though, Agile is very usable in the real world, as evidenced by its widespread adoption.

####Making a Choice
Adopting a methodology for this project is no easy choice. While Agile is usually the better choice, in this case there is no customer - so some of the disadvantages of waterfall don't apply: for example, the requirements are likely to be set from the beginning with no chance of change, and having meetings becomes rather moot. Taking cues from various techniques seems to be the optimal approach. A rigid and iterative approach would be useful to help avoid trying to concentrate on too many things at once, however the idea of a sprint approach, with designated reflection periods upon completion of tasks, would be beneficial for refinement and refactoring not only of code but of the ideas and user experience concepts behind the artefact. As such, since neither approach as a whole is entirely appropriate to the project in question, a loose, one-person adaptation of some of the best features from both will be used in progressing this project.

###Project Management Methodologies
####PRINCE2
PRINCE, or PRojects IN Controlled Environments, is a structured approach to managing projects used in the UK, Western Europe and Australia. Originally evolved from PROMPT2 (Project Resource Organisation Management and PLanning Technique), a methodology developed in 1975, the first iteration of PRINCE was used from 1989. In this early stage it was only really suited to IT projects, and a revision in 1996 - PRINCE2 - widened its application for use in non-IT projects as well. The methodology was again revised in 1999 to make it smaller and more lightweight.

PRINCE2 is now the de-facto standard for project management in many countries - including being widely used by the UK government and in the private sector - for a few reasons. Firstly, it does not require any license to use, making it appealing solely based on not having to pay any licensing fees, and secondly because of the substantial benefits of using such a widely-recognised methodology so commonly-understood. PRINCE2 is a very comprehensive approach, and covers the management of many aspects of a project, including definitions of roles and tasks for key team members, guidelines for risk management and the actual provision of outlines for reports and documents. It also covers when such reports should be written, and outlines a procedure for product development from conception through to completion (Bentley, C., 2002). However, because it is so comprehensive, PRINCE2 can be somewhat bureaucratic and full of red tape, and as such is best suited to larger projects.

####PMBOK
In contrast to the red tape of PRINCE2, PMBOK (the Project Management Book of Knowledge, the project management methodology prevalent in the United States) is more casual and more of a set of guidelines for managing projects rather than a structure to adhere to. First published as a white paper in 1987, and revised several times (the last major revision being in 2008), PMBOK's 'slogan', so to speak, is 'guidelines for managing most projects most of the time'. PMBOK is aware that it is not a one-size-fits-all solution and is thus more flexible and open to adaptation than the rigid PRINCE2. PMBOK's aim is to standardise project management techniques in five basic process groups: Initiation, Planning, Execution, Monitoring and Controlling, and Closure. It provides a best-fit approach to all of these areas, offering guidelines and over 40 processes that can be used or adapted for 'most' projects, and is designed to compliment other approaches to project work - for example the Capability Maturity Model (Integrated), or CMMI, a means of measuring the capability and maturity of a team to perform a specific task (PMI Standards Committee, 2004).

####Adapting a Methodology
Similar to with development techniques, unfortunately adapting a project management technique to cover a one-person outfit is not easy. While in a more traditional business project a methodology could be used, rigorously or otherwise, in this case the best approach is to simply take ideas and good practices from various sources and keep them in mind. Following a management technique strictly is next-to impossible - simply assigning the various outlined roles cannot be done without a workforce. However, using ideas from both PRINCE2 and PMBOK it is possible to come up with ideas of what needs to be considered when embarking on a project, of any scale, particularly during the planning stage. However, something that neither methodology covers in any great detail is risk management. This is something that will be important to cover in greater detail.

###Requirements Engineering
Requirements analysis and engineering can be critical to the success of a project. Being able to define the goals of a project, what it needs to fulfil, and being able to keep these in mind during the development process allows developers to focus on adhering to exactly what needs to be done during the creation process, ensuring that no essential features are missed out and that no time is wasted in designing and coding something that is not needed and perhaps not even wanted. The means in which requirements are gathered from an end-user base can vary greatly.

####Methods of Data Collection
All the many means of gathering data from users can fall under one of three categories: qualitative, quantitative and social. Quantitative data are data that can be expressed numerically, and as such is often shown in graphs and charts. The main method of collecting quantitative data is through questionnaires - the statistics retrieved through this means can be tallied up and put into visual formats. Qualitative data can be used to back this up: gathered via means such as direct observation or interviews, for example, it is possible to find out requirements in far more detail by using these methods, but it is far more time-consuming to accomplish. Finally, social data can be from a variety of sources - research findings, information from the media, or simply from use of logic. When beginning a project, depending on its scale and criticality, it may be desirable to use one or all of these sources to define its requirements (Palgrave.com,2011).

####Volere
The Volere template is a requirements specification and analysis template available for commercial use. It was first drafted in 1995, and published in 1999, to provide a structure and common language to the process of gathering requirements from various sources. Volere consists of three interconnected components: the Requirements Knowledge Structure, which deals with how different requirements relate to each other; the Requirements Stakeholders, concerning the priority of the work and the appropriate level of detail in accordance with the stakeholders' needs; and the Requirements Process, or the procedures for discovering requirements. While a commercial product, and thus mainly reserved for use by businesses with the resources to justify the monetary cost (and has been used in thousands of projects across the globe by such customers), the creators of Volere, James and Suzanne Robinson, have made it available to students for free, making it well worth taking a look at even if it is more suited to larger products with vested stakeholders.

Volere encourages one to consider the purpose of a project, as well as the motivations for creating a product and the intended final users of it. While it is very easy to get caught up in certain development habits, different products often require wholly different approaches. By having this template to fill in when planning a project, the development team (or business analysts under certain cases) can focus much better on what is needed of them, and thus potentially produce a better product and increase customer satisfaction. Additionally, Volere asks questions that may not often be thought of, such as defining maintenance requirements and specifying naming conventions to use during development (Robertson S. and Robertson J., 2008).

Being a modular process means that Volere is very flexible: it is possible to have a bespoke, 'bare-bones' version of the template which is simply used to gather the requirements of the project based on its budget, scope and time constraints, or the team can add more scope to the requirements gathering process. Volere is also designed to go hand-in-hand with processes such as use-case definitions, which will allow a greater extent of requirements to be defined based on the use-cases that have been envisioned.

####MoSCoW
The MoSCoW method is a prioritisation technique that comes into play during or after the gathering of requirements - meaning that the primary function of MoSCoW is not to be a means of gathering requirements, rather a means of defining their priorities in a very simple, self-explanatory and quick way. Developed by Dai Clegg of Oracle UK in 1994, MoSCoW is actually an acronym, standing for the four states of requirement (priorities) it encompasses. These are:  

*	Must Have
*	Should Have
*	Could Have
*	Won't Have

The simplicity and 'plain English' of these requirement prioritisations is incredibly useful when working with customers - simply handing a product owner a sheet containing these four headings and asking them to fill in their requirements is often viable, since the priorities' titles say everything necessary. *Must Have* defines the absolute necessities of the project - the outcomes that it must fulfil to be considered a success. If any of the Must requirements are not delivered, the project will have been a failure. *Should Have* requirements are critical to the project's success also, but are not essential to be included in the initial release. *Should* requirements often have workarounds, meaning that they can be semi-satisfied in some other way at least as a stopgap until their implementation.

The other two categories list requirements that are not essential for the deliverable to be considered 'complete'. *Could Have* requirements are 'nice-to-have'; things that would add to the value of a product and potentially the customer's satisfaction, but are only to be implemented if they are either judged simple enough to, or if there is time left over after the Must and Should Haves are finished. *Won't Have* requirements are those that the customer would like, but are the least critical items to be worked on. Sometimes referred to as *Would Haves*, these requirements are those that are not to be included in the current timescale of the project, but would definitely be up for contention in future revisions of the deliverable (Haughey, D., (n.d.)).

####Functional and Non-Functional Requirements
When gathering and prioritising requirements, no matter what method is used, it is useful to bear in mind that they fall into two distinct categories: functional and non-functional. To quote the Volere template, which is very clear on the definitions of the two:
> Functional requirements are the fundamental or essential subject matter of the product. They describe what the product has to do or what processing actions it must take.
> 
> Non-functional requirements are the properties that the functions must have, such as performance and usability. (Requirementsauthority.com, (n.d.)). 

Both types of requirement are essential to gather before beginning implementation, both types of requirement should be properly prioritised (using MoSCoW or otherwise), and both types of requirement count towards determining the level of success of a project upon its completion. In short, functional and non-functional requirements are equally important to the project's outcome - despite their name, non-functional requirements carry as much weight as functional.

####Evaluation of Methods
Gathering requirements for this project is going to be difficult without a customer or other user base to question. Observing and using applications that perform similar functions such as Steam or the iTunes Store will likely help in understanding what must be accomplished, and using some of the techniques outlined in Volere will be useful when considering, for example, the deployment requirements, or how use-cases and use-case diagrams (UCD's) can be used to add to the data already acquired. When it comes to prioritising the requirements once gathering is complete, MoSCoW is really the only suitable method. Many believe that other methods of requirements prioritisation are far inferior - its simplicity and comprehensiveness is a great combination, and other prioritisation techniques fall flat mostly by including numerical prioritisation rather than the far easier-to-understand worded method. Defining those Must/Should/Could requirements, however will likely be accomplished by observation of real-world applications and then prioritisation of their features. Obviously due to time and resource constraints the finished artefact will not have all the features of an application such as Steam, made over a period of years with the resources available to a company like Valve, and the Won't Have requirement category will likely be populated by very desirable features that must be dropped from this release of the application due to the constraints in time, budget and resources.

###Risk Management
In software development, a risk is an event that could potentially cause the project to fail to meet requirements. The level of a risk is an abstract, defined by its probability and the impact it will have. When planning a project, effective risk management is important to define and identify possible risks, and, through a process of analysis, prioritisation and careful planning, controlled. One of several approaches to risk management is the Software Engineering Institute's (SEI) Risk Management Programme.

####SEI Programme
This is a series of events to follow when performing risk management and planning. The first step consists of identifying as many risks as possible within the project's scope. With each risk that has been defined, there are five steps to go through to effectively plan for and manage each one.

1.	Analyse
2.	Plan
3.	Track
4.	Control
5.	Communicate

Every project has its risks. <a class="figref" href="#risk">Figure</a> shows some examples of potential risks to certain projects.

<div>
<figure id="risk">
<img src="img/systemrisks.png">
<figcaption>Risks within a System Context (Higuera, R.P., and Haimes, Y.Y., 1996)</figcaption>
</figure>
</div>

Different software development projects open up different categories which could be affected by risk: the project's schedule could be delayed, cost could be increased, quality could be decreased, performance hindered. While not all of these are relevant to this project (cost in particular doesn't come into it), a generic risk management process will be followed, so that a plan of action is in place in the event that significant areas of it come into jeopardy. Various techniques including brainstorming and incident investigation will be used to identify possible risks. From this, analysis on the likelihood of the risk occurring, alongside each risk's possible impact will allow for risks to be prioritised. From here, each risk can be monitored according to their priority (those which are highly likely or would cause the most damage will naturally be given the highest priorities during analysis) will be performed from the onset of this project. The risk management register can be seen in [Appendix C](#Appendices-2-3).

###Testing Methods
Software testing is a means of ensuring that a software product works as intended for the targeted userbase and purposes. Bugs in code are inevitable, and even if every use case possible is tested it is likely some will remain; there are far too many variables to quash them all. However, without testing many bugs the software will probably not be user-friendly, with bugs, crashes and memory leaks all possible. Unless testing is carried out to find and fix these issues, a user's perception of software will generally be bad, since bugs ruin the user experience. 

Since testing is such an important part of the software life cycle, many methods of testing exist to make it as convenient to integrate into software development as thorough at discovering bugs and unwanted features as it can be. Besides simply going through a program and manipulating every control, comparing the result to what was expected (a technique known as black-box testing), there are other methods which test the internal workings of the code itself to ensure that, logically, everything is happening as it should - known as white-box testing. While black-box testing is performed on a finished software product, testing can be performed during development as well. For example, a technique known as unit testing is commonly used to test individual functions or classes to ensure they can handle all possible inputs, and will output the correct results. Unit testing involves writing additional code to serve as 'test cases', which *assert* that functions exist and that their output when given certain parameters is as expected - even if the expected result is an error (Luo, L., 2001).

####Test-Driven Development
While commonly tests are written once software has been created and run on the code that has been written, a technique known as regression testing that has been around as long as software has, a method of software development - which actually in itself could be considered an iterative, Agile-based SDLC - known as Test-Driven Development (TDD) involves writing the unit tests first, before any code is written. TDD has become increasingly popular since its relatively recent invention in the early 2000s, and is used by large companies such as Microsoft and IBM. Its workflow, Red-Green-Refactor (Beck, K., 2003), is the best way to describe how it works.

1. Red: Write a test that describes how a code unit should work. It should FAIL when run, as the code it's attempting to test has not yet been written.
2. Green: Write code to make the test pass.
3. Refactor: When the test case passes, neaten up and reorganise the (potentially messy) code.
4. Repeat for another function

Test-Driven Development, then, changes the whole process of software testing to be proactive, rather than reacting to bugs. It can also serve as a means of defining low-level software requirements. However, a downside of using TDD is that it can take much longer to get started with a project, since a lot of time is spent writing tests. Given the time constraints on this project, and the planned very-iterative nature of development (which will be developed piece by piece, in order of priority, with additional features being added if there is time), testing (which will still remain of key importance) will not be given such a focus. Instead, a compromise will be made by performing a certain amount of regression testing coupled with extensive black-box testing, some of which will be carried out by third parties.
##Technologies
###Possible Technologies
Creating a client application, especially one that will be designed to run as a service, means several things. Firstly, performance must be considered - this application will be running constantly in the background of a system, and so its resource usage must be kept to a minimum. This straight away rules out interpreted languages such as Java, which in particular is often criticised for using up a large amount of RAM. Secondly, the choice of technology can limit which operating system(s) the program can run on. While various programming languages are universal, notably Java, and while methods of running technologies on alternative operating systems exist (for example, Mono allows .NET applications to run on Linux and Mac operating systems), to some extent choosing a programming language can choose the target operating system by default. Similarly, choosing an operating system to target can limit the available choice of technology. Making an informed decision of either operating system or technology to develop with is important from early on.

This project has been inspired by and likened to Steam, and other services that allow the downloading and purchase of games. While Steam is available on various platforms, most of its deliverables are restricted to the Windows operating system - most games are made on Windows - and as such it makes sense to follow suit and go where the market lies. Developing a Windows application also narrows down, as outlined above, the list of technologies that can be used somewhat - and additionally opens some doors.

The solution also involves a web service, which is for web stores to plug into to make purchases and communicate with the database. This brings into focus two more choices for technology: the language in which the web service will be written, and the DBMS (Database Management System) that will be used for the solution's persistent storage. One of the resources already available for this project was an Apache web server, which had MySQL and PostgreSQL installed, as well as PHP 5.3 and Ruby on Rails 2.3 - two great choices for a DBMS and two great choices of programming language for the web service.

####Decisions
Taking into account the above restrictions on choice of technologies and making an educated choice, the project will be developed using the following technologies.

Firstly, the native Windows application will be developed using the .NET framework. This is a powerful application development, deployment and runtime framework created by Microsoft, first released in late 2000, with the current version being .NET 4. Not only does .NET contain a huge amount of useful code libraries to develop against, it executes code in a software environment known as the Common Language Runtime (CLR). This wrapper performs tasks such as memory management and exception handling so the developer does not have to. Given the aforementioned necessity for minimal consumption of system resources coupled with the time constraints on this project, using this framework would prevent development becoming bogged down in optimisation and dealing with mundanities such as garbage disposal, and additionally the libraries available when using the .NET framework are invaluable.

Using this framework still offers a choice of programming language. There are a myriad of languages that can be compiled down to the CLR. However, the most popular of these is C# - and as such, C# .NET is the technology that will be used for creating this application. Additionally, the Integrated Development Environment (IDE) that will be used to develop in this language and framework is traditionally Microsoft Visual Studio - and available for this project is Visual Studio 2010 Ultimate Edition.

The choice of language for the web service is a much easier decision. Since the version of Ruby on Rails running on the web server available for this project is outdated (at time of writing, the current version is RoR 3.2), and seeing as there are several machines with XAMPP (Apache, MySQL, PHP and Perl) installed available for the purposes of this project, it makes sense for the web service to be developed using PHP. For the same reasons, the database will be created using MySQL. As far as development environment for PHP goes, many developers find that they don't require the power of a full IDE, instead using a powerful text editor with some IDE-like features. There are a selection of these available for this project: TextMate 1.6 for Mac, e-TextEditor for Windows, and Sublime Text 2, which is cross-platform. Due to personal preference, TextMate and e will be used for the development of the web service; which one will depend upon which operating system is being used at the time.

Finally, also available for the purposes of this project is a GitHub 'Micro' account, that allows private Git repositories to be created. Git is a very fast and lightweight source code management (SCM) and version control system, something that is incredibly useful for creating backups of files and for managing different versions of code using an intuitive 'branch' system, and GitHub is a web application that allows hosting and management of Git repositories. Because the Micro account allows creation of private repositories, there will be no issues with public leaks of confidential code. Therefore, Git and GitHub will be used for version control of this project.

###Deployment Technologies
An astute developer will be thinking about means of deploying his applications long before it reaches that time. Deployment techniques vary depending on the system: the web service being created for this project can be deployed by simply putting the program onto a compatible server - they will be accessed by making HTTP requests to the correct URI. Deploying a client application is a different matter. The program must somehow get onto the user's computer before it can be run. These days this is again commonly and easily achieved using the internet, although it's also (somewhat archaically now) possible to distribute on physical media (the irony of this given the whole concept of this project notwithstanding).

Applications for Windows are often distributed using installers. An installer allows the program to be added to the Start menu for easy access, allows all required libraries and other files to be placed in the correct locations, and any registry values to be created. However, since the application does not use the Windows registry, it would be feasible to distribute this application in a 'portable' format; simply it and all its required libraries in a zip archive. Often when this is done it is as an option to download a portable format instead of the installer. It makes sense to offer the user the choice of whether to download an installer or a portable archive, as the choice of which to download usually comes down to the user's preference.

When it comes to creating the installer, Visual Studio offers several options (MSDN, 2010). Built into the IDE is a tool called Setup and Deployment, which creates <code>.msi</code> installers. While this does not offer much customisation, it is very lightweight. If more features are needed, Microsoft provide the Windows Installer XML toolset (WIX), which uses XML to create a very powerful, very customisable <code>.msi</code> installer, amongst other things. However, WIX is very difficult to use, and as such has a very steep learning curve. Alternatively, there is a third-party plugin that has been incredibly successful even compared to the first-party tool, and as such has a somewhat large degree of brand awareness: InstallShield, by Flexera Software. This is a very easy-to-use installer creation process that creates a Setup.exe file. InstallShield has many strengths and tends to be more full-featured than the Visual Studio installer, but ultimately does the same job in a more bloated way. Although the Visual Studio Setup and Deployment process has its shortcomings, this project does not require a personalised installer or some of the features found in InstallShield or WIX.

###Pilot Study
Performing preliminary work before artefact production is a useful means of evaluating the feasibility of certain methods. One of the key parts of the solution is the communication between the two software components. To study this and its feasibility, two classes (in C#) were created well in advance of the actual implementation, as a pilot study. ListenerServer.cs was a simple application that ran an instance of TCPListener, listening for any IP address on port 31337, and upon receiving a message, displayed it on the console and sent back the current date and time. ListenerServerTest.cs was the other half of this application, which sent the message, and received and displayed the response.

<div>
<figure>
<pre class="prettyprint linenums">class ListenerServerTest
{
  static void Main(string[] args)
  {
    int port = 31337;
    string ip = "127.0.0.1";
    TcpClient tcpclient = new TcpClient(ip, port);
    Byte[] request = Encoding.ASCII.GetBytes("request");
	
	Console.WriteLine("Sending...");
	
	tcpclient.GetStream().Write(request, 0, request.Length);
	Byte[] response = new Byte[10];
    int bytesRead = tcpclient.GetStream().Read(response, 0, 10);
    
    Console.WriteLine("Response:   " + Encoding.ASCII.GetString(response));
    Console.ReadLine();
    tcpclient.Close();
  }
}</pre>
<figcaption>The preliminary code that was used to test ListenerServer.cs</figcaption>
</figure>
</div>